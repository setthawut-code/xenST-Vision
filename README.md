# Spatial Transcriptomics Prediction from H&E Images

‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏¢‡∏µ‡∏ô‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û H&E ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Deep Learning

Spatial gene expression prediction from H&E histology images using Deep Learning, trained with Xenium data.

## Features / ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥

- üñºÔ∏è **H&E Image Input** - Upload standard histology images
- ÔøΩ **Multi-Scale Transformer** - Swin/ViT encoder for capturing details at multiple resolutions (Wave A)
- üï∏Ô∏è **Spatial Graph Modeling** - Optional GNN integration for spatial context (Wave A)
- ÔøΩüß¨ **Gene Expression Prediction** - Predict 50+ genes simultaneously  
- üó∫Ô∏è **Spatial Mapping** - Visualize expression across tissue
- üìä **Interactive Plots** - Explore results with Plotly
- üåê **Bilingual Interface** - Thai/English web UI
- üíæ **Export Results** - Download predictions as CSV

## Quick Start / ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### Installation / ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

```bash
# Clone repository
git clone https://github.com/setthawut-code/xenST-Vision.git
cd ProjectXenium

# Install dependencies
pip install -r requirements.txt
```

### Training / ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

**Legacy (ResNet50):**
```bash
python src/train.py --config config/config.yaml
```

**Wave A (Multi-Scale + GNN):**
```bash
python src/train.py --config configs/experiment_multiscale.yaml
```

**Verification / ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á:**

Run the mini-benchmark to check model instantiation and metrics:
```bash
python3 verify_wave_a.py
# or
jupyter notebook notebooks/mini_benchmark.ipynb
```

### Web Interface / ‡πÄ‡∏ß‡πá‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ü‡∏ã

```bash
# Start web app
python web/app.py

# With public sharing
python web/app.py --share

# Open browser to http://localhost:7860
```

### Inference / ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

```bash
# Command line prediction
python src/inference.py \
    --image path/to/he_image.png \
    --checkpoint checkpoints/best_model.pth \
    --output output/results
```

## Model Architecture / ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•

**Wave A Model:**
- **Backbone**: Multi-Scale Swin Transformer (via `timm`) or ViT
- **Context**: Optional Spatial GNN (Graph Neural Network)
- **Input**: Multi-scale H&E patches (e.g., 224x224, 512x512)
- **Output**: Gene expression vector (variable genes) + Tissue classification
- **Loss**: Regression Loss (MSE) + Classification Loss

**Baseline Model (Legacy):**
- **Encoder**: ResNet50 (pretrained on ImageNet)
- **Decoder**: 3-layer MLP regression head
- **Loss**: Mean Squared Error (MSE)

**Performance:**
- Expected Pearson correlation: 0.3-0.5
- Training time: 6-12 hours (GPU)  
- Inference: ~1-3 seconds per patch

## Project Structure / ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

```
ProjectXenium/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml          # Configuration
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model.py            # Model architecture
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py   # Data loading
‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Training script
‚îÇ   ‚îú‚îÄ‚îÄ inference.py        # Inference script
‚îÇ   ‚îî‚îÄ‚îÄ utils.py            # Utilities
‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îî‚îÄ‚îÄ app.py              # Gradio web interface
‚îú‚îÄ‚îÄ data/                   # Data directory
‚îú‚îÄ‚îÄ checkpoints/            # Trained models
‚îú‚îÄ‚îÄ logs/                   # TensorBoard logs
‚îú‚îÄ‚îÄ output/                 # Prediction results
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Configuration / ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

Edit `config/config.yaml` to customize:
- Number of genes to predict
- Training hyperparameters
- Data augmentation
- Model architecture

## Data / ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### Xenium Data Format

Expected structure:
```
xenium_output/
‚îú‚îÄ‚îÄ cell_feature_matrix.h5  # Gene expression
‚îú‚îÄ‚îÄ cells.csv.gz             # Cell locations
‚îú‚îÄ‚îÄ transcripts.csv.gz       # Transcripts
‚îî‚îÄ‚îÄ morphology.ome.tif       # H&E image
```

### Public Datasets

Download from 10x Genomics:
- Human breast cancer (FFPE)
- Mouse brain
- Human lung cancer

Link: https://www.10xgenomics.com/datasets

## Web Interface Screenshots

The bilingual web interface provides:
1. **Image Upload** - Drag & drop H&E images
2. **Model Selection** - Choose trained checkpoint
3. **Gene Selection** - Pick gene to visualize
4. **Interactive Map** - Plotly spatial heatmap
5. **Download** - Export predictions as CSV

## Requirements / ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏ö

**Hardware:**
- GPU with ‚â•16GB VRAM (24GB+ recommended for training)
- 32GB+ RAM
- 50GB+ storage

**Software:**
- Python 3.8+
- CUDA 11.0+ (for GPU)
- PyTorch 2.0+

## Troubleshooting / ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤

**Model not found:**
```bash
# Train model first
python src/train.py --config config/config.yaml
```

**Out of memory:**
```yaml
# Reduce batch size in config.yaml
training:
  batch_size: 16  # Try 8 or 4
```

**No GPU available:**
```yaml
# Use CPU in config.yaml
inference:
  device: "cpu"
```

## Citation / ‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

If you use this code, please cite:
```bibtex
@software{spatial_transcriptomics_prediction,
  title={Spatial Transcriptomics Prediction from H\&E Images},
  author={Setthawut Intarapradit},
  year={2025}
}
```

## License / ‡πÉ‡∏ö‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï

MIT License

## Acknowledgments / ‡∏Å‡∏¥‡∏ï‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®

- Built with PyTorch, Gradio, Scanpy
- Inspired by DeepSpot, CarHE, and Hist2ST
- Xenium data from 10x Genomics

---

**Made with ‚ù§Ô∏è for computational pathology & spatial biology**
